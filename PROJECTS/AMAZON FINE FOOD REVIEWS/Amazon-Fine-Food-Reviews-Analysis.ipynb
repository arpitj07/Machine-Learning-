{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Fine Food Reviews Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "os.chdir(\"/kaggle/input/amazon-reviews/\")\n",
    "from dataset import *\n",
    "from utils import *\n",
    "os.chdir(\"/kaggle/working/\")\n",
    "\n",
    "# Modules for handling text data\n",
    "from sklearn.feature_extraction.text import TfidfTransformer , TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "#Evaluation Metrics\n",
    "from sklearn.metrics import auc , roc_curve , confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "sqldatapath = \"../input/amazon-fine-food-reviews/database.sqlite\"\n",
    "\n",
    "filter_data= SQLdata(sqldatapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Prepocessing\n",
    "* Converting the **Score Columm** in to Positive ( score >3 ) and Negative ( score <3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "actualScore = filter_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "filter_data['Score'] = positiveNegative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Cleaning: Deduplication\n",
    "There are lot of entries which are duplicate and should be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32313</th>\n",
       "      <td>35174</td>\n",
       "      <td>B001ATMQK2</td>\n",
       "      <td>AZY10LLTJ71NX</td>\n",
       "      <td>undertheshrine \"undertheshrine\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1296691200</td>\n",
       "      <td>Have you seen how much Ranch 99 is trying to c...</td>\n",
       "      <td>I bought this 6 pack because for the price tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306745</th>\n",
       "      <td>332195</td>\n",
       "      <td>B001P7AXXG</td>\n",
       "      <td>AZY10LLTJ71NX</td>\n",
       "      <td>undertheshrine \"undertheshrine\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1303776000</td>\n",
       "      <td>BEST MICROWAVE POPCORN EVER!!!!</td>\n",
       "      <td>This popcorn is probably the best microwave po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307530</th>\n",
       "      <td>333057</td>\n",
       "      <td>B000MYW2ZA</td>\n",
       "      <td>AZY10LLTJ71NX</td>\n",
       "      <td>undertheshrine \"undertheshrine\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1334707200</td>\n",
       "      <td>works for me.  lost 10-15 pounds my first month</td>\n",
       "      <td>I was recommended to try green tea extract to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314733</th>\n",
       "      <td>340773</td>\n",
       "      <td>B0043CVIBG</td>\n",
       "      <td>AZY10LLTJ71NX</td>\n",
       "      <td>undertheshrine \"undertheshrine\"</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1303776000</td>\n",
       "      <td>girl scout thin mint in disguise</td>\n",
       "      <td>if you love thin mint cookies that the girl sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374253</th>\n",
       "      <td>404703</td>\n",
       "      <td>B006P7E5ZI</td>\n",
       "      <td>AZY10LLTJ71NX</td>\n",
       "      <td>undertheshrine \"undertheshrine\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1334707200</td>\n",
       "      <td>works for me.  lost 10-15 pounds my first month</td>\n",
       "      <td>I was recommended to try green tea extract to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId         UserId                      ProfileName  \\\n",
       "32313    35174  B001ATMQK2  AZY10LLTJ71NX  undertheshrine \"undertheshrine\"   \n",
       "306745  332195  B001P7AXXG  AZY10LLTJ71NX  undertheshrine \"undertheshrine\"   \n",
       "307530  333057  B000MYW2ZA  AZY10LLTJ71NX  undertheshrine \"undertheshrine\"   \n",
       "314733  340773  B0043CVIBG  AZY10LLTJ71NX  undertheshrine \"undertheshrine\"   \n",
       "374253  404703  B006P7E5ZI  AZY10LLTJ71NX  undertheshrine \"undertheshrine\"   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "32313                      1                       1  Positive  1296691200   \n",
       "306745                     1                       1  Positive  1303776000   \n",
       "307530                     0                       0  Positive  1334707200   \n",
       "314733                     4                       4  Positive  1303776000   \n",
       "374253                     0                       0  Positive  1334707200   \n",
       "\n",
       "                                                  Summary  \\\n",
       "32313   Have you seen how much Ranch 99 is trying to c...   \n",
       "306745                    BEST MICROWAVE POPCORN EVER!!!!   \n",
       "307530    works for me.  lost 10-15 pounds my first month   \n",
       "314733                   girl scout thin mint in disguise   \n",
       "374253    works for me.  lost 10-15 pounds my first month   \n",
       "\n",
       "                                                     Text  \n",
       "32313   I bought this 6 pack because for the price tha...  \n",
       "306745  This popcorn is probably the best microwave po...  \n",
       "307530  I was recommended to try green tea extract to ...  \n",
       "314733  if you love thin mint cookies that the girl sc...  \n",
       "374253  I was recommended to try green tea extract to ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_data[filter_data['UserId']=='AZY10LLTJ71NX']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the above example we see that **UserID , ProfileName , Time , Summary , Text** are same. This is because the user has given review of a product which has different varieties. For exampple : A user has reviewed a potato chips of one flavour but the the chips has different flavour on the same page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the data by Product ID \n",
    "sorted_data = filter_data.sort_values('ProductId' , ascending=True , axis=0 , inplace=False)\n",
    "\n",
    "# Dropping the duplicates\n",
    "final = sorted_data.drop_duplicates(subset={'UserId' , 'ProfileName', 'Time' , 'Text'} , inplace=False , keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**:- It was also seen that in two rows given below the value of HelpfulnessNumerator is greater than HelpfulnessDenominator which is not practically possible hence these two rows too are removed from calcualtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41159</th>\n",
       "      <td>44737</td>\n",
       "      <td>B001EQ55RW</td>\n",
       "      <td>A2V0I904FH7ABY</td>\n",
       "      <td>Ram</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1212883200</td>\n",
       "      <td>Pure cocoa taste with crunchy almonds inside</td>\n",
       "      <td>It was almost a 'love at first bite' - the per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59301</th>\n",
       "      <td>64422</td>\n",
       "      <td>B000MIDROQ</td>\n",
       "      <td>A161DK06JJMCYF</td>\n",
       "      <td>J. E. Stephens \"Jeanne\"</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1224892800</td>\n",
       "      <td>Bought This for My Son at College</td>\n",
       "      <td>My son loves spaghetti so I didn't hesitate or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id   ProductId          UserId              ProfileName  \\\n",
       "41159  44737  B001EQ55RW  A2V0I904FH7ABY                      Ram   \n",
       "59301  64422  B000MIDROQ  A161DK06JJMCYF  J. E. Stephens \"Jeanne\"   \n",
       "\n",
       "       HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "41159                     3                       2  Positive  1212883200   \n",
       "59301                     3                       1  Positive  1224892800   \n",
       "\n",
       "                                            Summary  \\\n",
       "41159  Pure cocoa taste with crunchy almonds inside   \n",
       "59301             Bought This for My Son at College   \n",
       "\n",
       "                                                    Text  \n",
       "41159  It was almost a 'love at first bite' - the per...  \n",
       "59301  My son loves spaghetti so I didn't hesitate or...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_data[filter_data['HelpfulnessNumerator']> filter_data['HelpfulnessDenominator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final[final['HelpfulnessNumerator']< final['HelpfulnessDenominator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final shape of the data is (68271, 10)\n",
      "The count of positive and negative reviews \n",
      " Positive    40027\n",
      "Negative    28244\n",
      "Name: Score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('The final shape of the data is',final.shape)\n",
    "print('The count of positive and negative reviews \\n', final['Score'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Text Processing: Stemming , Stop Words removal , Lemmatization\n",
    "\n",
    "Hence in the Preprocessing phase we do the following in the order below:-\n",
    "\n",
    "1. Begin by removing the html tags\n",
    "2. Remove any punctuations or limited set of special characters like , or . or # etc.\n",
    "3. Check if the word is made up of english letters and is not alpha-numeric\n",
    "4. Check to see if the length of the word is greater than 2 (as it was researched that there is no adjective in 2-letters)\n",
    "5. Convert the word to lowercase\n",
    "6. Remove Stopwords\n",
    "7. Finally Snowball Stemming the word (it was obsereved to be better than Porter Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the stopwords from English Language\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize the Snowball stemming\n",
    "snow = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'same', 'couldn', 'too', 'of', 'will', 'after', 'again', 'him', 'now', 'mightn', 'did', 'yourselves', 'mustn', 'no', \"it's\", 'its', 'then', 'wouldn', 'won', \"wouldn't\", 'before', 'own', 'here', 'don', 'been', 'yourself', 'while', 'few', 'them', 'that', \"shouldn't\", 'why', 'does', 'd', 's', 'these', 'hasn', 'any', 'where', \"should've\", 'between', 'other', 'some', 'her', 'ain', 'the', 'be', 'all', 'at', 'which', 'it', 'if', 'with', 'off', 'didn', 'there', 'has', 'had', 'an', \"couldn't\", 'needn', 'so', 't', 'just', 'wasn', 'should', 'shan', 'myself', 'above', 'out', 'shouldn', 'more', 'below', 'our', \"mightn't\", \"you've\", 'being', 'about', 've', 'll', 'but', 'i', 'hadn', \"hasn't\", \"weren't\", \"you're\", 'those', 'or', 'doesn', 'each', 'from', 'because', 'were', \"you'll\", 'by', 'his', \"aren't\", \"you'd\", \"haven't\", 'over', 'hers', 'y', 'for', 'she', 'you', 'most', 'me', 'we', 'what', 'themselves', 'further', 'is', \"that'll\", 'ma', 'he', 'himself', 'in', 'do', 'than', \"wasn't\", 'o', 'when', \"don't\", 'doing', 'against', 'such', 'aren', 'am', \"she's\", 'to', 'yours', 'my', 'was', 'are', 'up', 'weren', 'theirs', 'under', \"isn't\", 'through', 'they', 'not', \"doesn't\", 'herself', \"shan't\", 'and', 'once', 'can', 'itself', 're', 'a', 'both', 'isn', 'your', \"needn't\", \"mustn't\", 'down', 'until', 'who', 'nor', 'ourselves', 'ours', 'as', 'during', 'having', 'very', 'm', \"hadn't\", 'have', 'only', 'this', \"didn't\", 'whom', 'haven', 'how', 'on', 'their', \"won't\", 'into'}\n"
     ]
    }
   ],
   "source": [
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasti\n"
     ]
    }
   ],
   "source": [
    "print(snow.stem('tasty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68271/68271 [01:47<00:00, 634.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total time to run the cell:  107.55213165283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i =0\n",
    "str1 = ' '\n",
    "final_string = []\n",
    "all_pos_words = []\n",
    "all_neg_words = []\n",
    "s = \" \"\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "start = time.time()\n",
    "\n",
    "for sent in tqdm(final['Text'].values):\n",
    "    filtered_sent =[]\n",
    "    sent = cleanhtml(sent)  # remove HTML tags\n",
    "    for w in sent.split():  \n",
    "        for clean_words in cleanpunc(w).split():\n",
    "            if ((clean_words.isalpha()) & (len(clean_words)>2)):\n",
    "                if (clean_words.lower() not in stop):\n",
    "                    s = (snow.stem(clean_words.lower())).encode('utf8')\n",
    "                    filtered_sent.append(s)   # storing all filterd words \n",
    "                    if (final['Score'].values[i] == 'Positive'):\n",
    "                        all_pos_words.append(s)  # storing all pos words\n",
    "                    if (final['Score'].values[i] == 'Negative'):\n",
    "                        all_neg_words.append(s)  # storing all neg words\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "    str1 = b\" \".join(filtered_sent)\n",
    "    final_string.append(str1)\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('The total time to run the cell: ', (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['CleanedText'] = final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138691</th>\n",
       "      <td>150509</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3CMRKGE0P909G</td>\n",
       "      <td>Teresa</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1018396800</td>\n",
       "      <td>A great way to learn the months</td>\n",
       "      <td>This is a book of poetry about the months of t...</td>\n",
       "      <td>b'book poetri month year goe month cute littl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138707</th>\n",
       "      <td>150525</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2QID6VCFTY51R</td>\n",
       "      <td>Rick</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1025481600</td>\n",
       "      <td>In December it will be, my snowman's anniversa...</td>\n",
       "      <td>My daughter loves all the \"Really Rosie\" books...</td>\n",
       "      <td>b'daughter love realli rosi book introduc real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138708</th>\n",
       "      <td>150526</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3E9QZFE9KXH8J</td>\n",
       "      <td>R. Mitchell</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1129507200</td>\n",
       "      <td>awesome book poor size</td>\n",
       "      <td>This is one of the best children's books ever ...</td>\n",
       "      <td>b'one best children book ever written mini ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138709</th>\n",
       "      <td>150529</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A25ACLV5KPB4W</td>\n",
       "      <td>Matt Hetling \"Matt\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1108425600</td>\n",
       "      <td>Nice cadence, catchy rhymes</td>\n",
       "      <td>In June&lt;br /&gt;I saw a charming group&lt;br /&gt;of ro...</td>\n",
       "      <td>b'june saw charm group rose begin droop pep ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138676</th>\n",
       "      <td>150493</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AMX0PJKV4PPNJ</td>\n",
       "      <td>E. R. Bird \"Ramseelbird\"</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1096416000</td>\n",
       "      <td>Read it once. Read it twice. Reading Chicken S...</td>\n",
       "      <td>These days, when a person says, \"chicken soup\"...</td>\n",
       "      <td>b'day person say chicken soup probabl go follo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId               ProfileName  \\\n",
       "138691  150509  0006641040  A3CMRKGE0P909G                    Teresa   \n",
       "138707  150525  0006641040  A2QID6VCFTY51R                      Rick   \n",
       "138708  150526  0006641040  A3E9QZFE9KXH8J               R. Mitchell   \n",
       "138709  150529  0006641040   A25ACLV5KPB4W       Matt Hetling \"Matt\"   \n",
       "138676  150493  0006641040   AMX0PJKV4PPNJ  E. R. Bird \"Ramseelbird\"   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "138691                     3                       4  Positive  1018396800   \n",
       "138707                     1                       2  Positive  1025481600   \n",
       "138708                    11                      18  Negative  1129507200   \n",
       "138709                     0                       1  Positive  1108425600   \n",
       "138676                    71                      72  Positive  1096416000   \n",
       "\n",
       "                                                  Summary  \\\n",
       "138691                    A great way to learn the months   \n",
       "138707  In December it will be, my snowman's anniversa...   \n",
       "138708                             awesome book poor size   \n",
       "138709                        Nice cadence, catchy rhymes   \n",
       "138676  Read it once. Read it twice. Reading Chicken S...   \n",
       "\n",
       "                                                     Text  \\\n",
       "138691  This is a book of poetry about the months of t...   \n",
       "138707  My daughter loves all the \"Really Rosie\" books...   \n",
       "138708  This is one of the best children's books ever ...   \n",
       "138709  In June<br />I saw a charming group<br />of ro...   \n",
       "138676  These days, when a person says, \"chicken soup\"...   \n",
       "\n",
       "                                              CleanedText  \n",
       "138691  b'book poetri month year goe month cute littl ...  \n",
       "138707  b'daughter love realli rosi book introduc real...  \n",
       "138708  b'one best children book ever written mini ver...  \n",
       "138709  b'june saw charm group rose begin droop pep ch...  \n",
       "138676  b'day person say chicken soup probabl go follo...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = sqlite3.connect('/kaggle/working/final.sqlite')\n",
    "# c= conn.cursor()\n",
    "# conn.text_factory = str\n",
    "# final.to_sql('Amazon Reviews' , conn , if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Bag of Words\n",
    "* n this model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "final_count = count_vect.fit_transform(final['Text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of vectors <class 'scipy.sparse.csr.csr_matrix'>\n",
      "THE shape of the vector (68271, 59870)\n"
     ]
    }
   ],
   "source": [
    "print(\"The type of vectors\", type(final_count))\n",
    "print('THE shape of the vector', final_count.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Bi-Grams and n-grams\n",
    "\n",
    "* an n-gram is a contiguous sequence of n items from a given sample of text or speech. The items can be phonemes, syllables, letters, words or base pairs according to the application. The n-grams typically are collected from a text or speech corpus. When the items are words, n-grams may also be called shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common positive words:  [(b'like', 20581), (b'tast', 19019), (b'good', 16179), (b'use', 15308), (b'flavor', 14467), (b'one', 14230), (b'product', 14100), (b'great', 13101), (b'coffe', 12531), (b'love', 12030), (b'tri', 11641), (b'tea', 11516), (b'get', 10756), (b'make', 10541), (b'would', 8536), (b'food', 8365), (b'time', 7862), (b'realli', 7651), (b'eat', 7613), (b'buy', 7464)]\n",
      "\n",
      "Most Common positive words:  [(b'tast', 16926), (b'like', 16111), (b'product', 14802), (b'one', 10266), (b'would', 9005), (b'tri', 8972), (b'flavor', 8720), (b'use', 7665), (b'food', 7460), (b'good', 7428), (b'coffe', 7179), (b'get', 7123), (b'buy', 6905), (b'order', 6404), (b'tea', 5831), (b'even', 5635), (b'amazon', 5524), (b'box', 5516), (b'make', 5154), (b'eat', 4989)]\n"
     ]
    }
   ],
   "source": [
    "#computing frequently occuring words in positive rewiew and negative rewiew\n",
    "freq_pos = nltk.FreqDist(all_pos_words)\n",
    "freq_neg = nltk.FreqDist(all_neg_words)\n",
    "\n",
    "print(\"Most Common positive words: \" , freq_pos.most_common(20))\n",
    "print(\"\\nMost Common positive words: \" , freq_neg.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVATION:** As it can be seen many words in positive and negative rewiew overlap. So its a good idea to consider the pair of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi-gram \n",
    "\n",
    "count_vect = CountVectorizer(ngram_range=(1,2))\n",
    "final_bi_gram_count = count_vect.fit_transform(final['Text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of new vector matrix after Bi_gram  (68271, 1163345)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of new vector matrix after Bi_gram \" , final_bi_gram_count.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. TF-IDF\n",
    "\n",
    "* In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling. The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "fina__tfidf = tf_idf_vect.fit_transform(final['Text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the vector after TF-IDF:  (68271, 1163345)\n"
     ]
    }
   ],
   "source": [
    "print(\"the shape of the vector after TF-IDF: \", fina__tfidf.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1163345"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = tf_idf_vect.get_feature_names()\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bake so',\n",
       " 'bake solved',\n",
       " 'bake some',\n",
       " 'bake something',\n",
       " 'bake special',\n",
       " 'bake stuff',\n",
       " 'bake such',\n",
       " 'bake sugar',\n",
       " 'bake sweets',\n",
       " 'bake than']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking few features \n",
    "features[109000:109010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVATION**: These words are Bi-grams but there may be some Uni-grams as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# convert a row of sparsematrix into array\n",
    "print(fina__tfidf[3,:].toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting top n features of TF-IDF\n",
    "\n",
    "def top_n_feat(row , features , top=25):\n",
    "    \n",
    "    topn_ids= np.argsort(row)[::-1][:top]  #sorting the vector and reversing and pick top 25\n",
    "    topn_feat = [(features[i] , row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(topn_feat)\n",
    "    df.columns = [ 'Features' , 'tfidf']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tfidf = top_n_feat(fina__tfidf[2,:].toarray()[0] , features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bewilderment to</td>\n",
       "      <td>0.190952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is mini</td>\n",
       "      <td>0.190952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bewilderment</td>\n",
       "      <td>0.190952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my bewilderment</td>\n",
       "      <td>0.190952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mini version</td>\n",
       "      <td>0.190952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>books ever</td>\n",
       "      <td>0.190952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>best children</td>\n",
       "      <td>0.190952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>children books</td>\n",
       "      <td>0.190952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>not portrayed</td>\n",
       "      <td>0.190952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>email regarding</td>\n",
       "      <td>0.184183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>written but</td>\n",
       "      <td>0.184183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>portrayed as</td>\n",
       "      <td>0.184183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>portrayed</td>\n",
       "      <td>0.179381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>regarding my</td>\n",
       "      <td>0.172612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>product sent</td>\n",
       "      <td>0.170038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ever written</td>\n",
       "      <td>0.170038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>priced for</td>\n",
       "      <td>0.146309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>book and</td>\n",
       "      <td>0.144666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>got no</td>\n",
       "      <td>0.144666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sent an</td>\n",
       "      <td>0.138607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>the book</td>\n",
       "      <td>0.134452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>no response</td>\n",
       "      <td>0.128957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>is over</td>\n",
       "      <td>0.121918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>over priced</td>\n",
       "      <td>0.121653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>an email</td>\n",
       "      <td>0.120388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Features     tfidf\n",
       "0   bewilderment to  0.190952\n",
       "1           is mini  0.190952\n",
       "2      bewilderment  0.190952\n",
       "3   my bewilderment  0.190952\n",
       "4      mini version  0.190952\n",
       "5        books ever  0.190952\n",
       "6     best children  0.190952\n",
       "7    children books  0.190952\n",
       "8     not portrayed  0.190952\n",
       "9   email regarding  0.184183\n",
       "10      written but  0.184183\n",
       "11     portrayed as  0.184183\n",
       "12        portrayed  0.179381\n",
       "13     regarding my  0.172612\n",
       "14     product sent  0.170038\n",
       "15     ever written  0.170038\n",
       "16       priced for  0.146309\n",
       "17         book and  0.144666\n",
       "18           got no  0.144666\n",
       "19          sent an  0.138607\n",
       "20         the book  0.134452\n",
       "21      no response  0.128957\n",
       "22          is over  0.121918\n",
       "23      over priced  0.121653\n",
       "24         an email  0.120388"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Word2Vec\n",
    "\n",
    "* Word2vec takes as its input a large corpus of text and produces a vector space, typically of several hundred dimensions, with each unique word in the corpus being assigned a corresponding vector in the space. Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located in close proximity to one another in the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec , KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('../input/gnewsvector/GoogleNews-vectors-negative300.bin' , binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76640123"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('woman' , 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('man', 0.7664012312889099),\n",
       " ('girl', 0.7494640946388245),\n",
       " ('teenage_girl', 0.7336829900741577),\n",
       " ('teenager', 0.631708562374115),\n",
       " ('lady', 0.6288785934448242),\n",
       " ('teenaged_girl', 0.6141784191131592),\n",
       " ('mother', 0.607630729675293),\n",
       " ('policewoman', 0.6069462299346924),\n",
       " ('boy', 0.5975908041000366),\n",
       " ('Woman', 0.5770983099937439)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68271/68271 [00:20<00:00, 3393.78it/s]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from tqdm import tqdm\n",
    "i=0\n",
    "list_of_sent =[]\n",
    "\n",
    "for sent in tqdm(final['Text'].values):\n",
    "    filtered_sent=[]\n",
    "    sent= cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleanW in cleanpunc(w).split():\n",
    "            if (cleanW.isalpha()):\n",
    "                filtered_sent.append(cleanW.lower())\n",
    "            else:\n",
    "                continue\n",
    "    list_of_sent.append(filtered_sent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a book of poetry about the months of the year.  It goes through each month and has a cute little poem to go along with it.  I love this book because it is a really fun way to learn the months and the poems are very creative. The author's purpose for writing this book was to give children a fun way to learn the months.  The children can also learn things about poetry and rhythm through reading this book.\n"
     ]
    }
   ],
   "source": [
    "print(final['Text'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'book', 'of', 'poetry', 'about', 'the', 'months', 'of', 'the', 'year', 'it', 'goes', 'through', 'each', 'month', 'and', 'has', 'a', 'cute', 'little', 'poem', 'to', 'go', 'along', 'with', 'it', 'i', 'love', 'this', 'book', 'because', 'it', 'is', 'a', 'really', 'fun', 'way', 'to', 'learn', 'the', 'months', 'and', 'the', 'poems', 'are', 'very', 'creative', 'the', 'author', 's', 'purpose', 'for', 'writing', 'this', 'book', 'was', 'to', 'give', 'children', 'a', 'fun', 'way', 'to', 'learn', 'the', 'months', 'the', 'children', 'can', 'also', 'learn', 'things', 'about', 'poetry', 'and', 'rhythm', 'through', 'reading', 'this', 'book']\n"
     ]
    }
   ],
   "source": [
    "print(list_of_sent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18438\n"
     ]
    }
   ],
   "source": [
    "word2vecmodel = gensim.models.Word2Vec(list_of_sent , min_count=5, size=50 , workers=4)\n",
    "words = list(word2vecmodel.wv.vocab)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yummy', 0.862500011920929),\n",
       " ('satisfying', 0.8510292172431946),\n",
       " ('delicious', 0.8106536865234375),\n",
       " ('filling', 0.803415834903717),\n",
       " ('versatile', 0.7963504791259766),\n",
       " ('flavorful', 0.7885638475418091),\n",
       " ('nutritious', 0.7743555307388306),\n",
       " ('moist', 0.7722365856170654),\n",
       " ('crunchy', 0.7326051592826843),\n",
       " ('salty', 0.7304224967956543)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vecmodel.wv.most_similar('tasty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('okay', 0.6167913675308228),\n",
       " ('resemble', 0.604689359664917),\n",
       " ('alright', 0.5949361324310303),\n",
       " ('prefer', 0.5874310731887817),\n",
       " ('mean', 0.5840886831283569),\n",
       " ('gross', 0.5762603282928467),\n",
       " ('think', 0.574055016040802),\n",
       " ('burnt', 0.572217583656311),\n",
       " ('dislike', 0.5696036219596863),\n",
       " ('fake', 0.5673271417617798)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vecmodel.wv.most_similar('like')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like\n"
     ]
    }
   ],
   "source": [
    "count_vect_feat = count_vect.get_feature_names()\n",
    "count_vect_feat.index('like')\n",
    "print(count_vect_feat[574544])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Average Word2Vec , TF-IDF weighted Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 52558/68271 [00:20<00:06, 2442.34it/s]/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "100%|██████████| 68271/68271 [00:27<00:00, 2517.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Compute Word to vector\n",
    "\n",
    "sent_vectors = []\n",
    "\n",
    "for sent in tqdm(list_of_sent):    # looping over all the rewiew\n",
    "    sent_vec = np.zeros(50)         # len of the word vector\n",
    "    count_word =0                  #count the valid word in the sentence\n",
    "    for word in sent:              #looping over each word in the sentence\n",
    "        try:\n",
    "            vec =word2vecmodel.wv[word] #converting each word to vector\n",
    "            sent_vec+=vec                #adding vector to the defined vector\n",
    "            count_word+=1               #counting the number of words converted. used later for average\n",
    "        except:\n",
    "            continue\n",
    "    sent_vec/= count_word\n",
    "    sent_vectors.append(sent_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68271\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(sent_vectors))\n",
    "print(len(sent_vectors[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF weighted W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:13<00:00,  5.37s/it]\n"
     ]
    }
   ],
   "source": [
    "tfidf_sent_vectors =[]\n",
    "row=0\n",
    "for sent in tqdm(list_of_sent[:10]):\n",
    "    sent_vec= np.zeros(50)\n",
    "    weight_sum=0\n",
    "    for word in sent:\n",
    "        try:\n",
    "            vec = word2vecmodel.wv[word]\n",
    "            tfidf = fina__tfidf[row , features.index(word)]\n",
    "            sent_vec+= (vec*tfidf)\n",
    "            weight_sum +=tfidf\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec/=weight_sum\n",
    "    tfidf_sent_vectors.append(sent_vec)\n",
    "    row+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
